# Risk Assessment Module - Architecture & Flow

## ğŸ—ï¸ Overall Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface Layer                       â”‚
â”‚  /ai-systems/[id] â†’ Risk Assessments Tab                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Components                        â”‚
â”‚  â€¢ RiskTable.tsx (displays assessments)                      â”‚
â”‚  â€¢ RiskForm.tsx (creates new assessment)                     â”‚
â”‚  â€¢ RiskDetail.tsx (shows assessment details)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼ HTTP Requests
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Routes (Next.js)                       â”‚
â”‚  POST /api/ai-systems/[id]/risk-assessments                  â”‚
â”‚  GET  /api/ai-systems/[id]/risk-assessments                  â”‚
â”‚  GET  /api/risk-assessments/[assessmentId]                   â”‚
â”‚  PUT  /api/risk-assessments/[assessmentId]                   â”‚
â”‚  GET  /api/ai-systems/[id]/overall-risk                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼ Supabase Client
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Database Layer (PostgreSQL)               â”‚
â”‚  risk_assessments table                                      â”‚
â”‚  â€¢ RLS Policies (security)                                   â”‚
â”‚  â€¢ Indexes (performance)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow Diagram

### 1. Creating a Risk Assessment

```
User Action
    â”‚
    â–¼
[Opens /ai-systems/[id]]
    â”‚
    â–¼
[Clicks "New Assessment" button]
    â”‚
    â–¼
[Fills RiskForm.tsx]
    â”‚
    â”œâ”€ Category: bias/robustness/privacy/explainability
    â”œâ”€ Risk Level: low/medium/high
    â”œâ”€ Summary: text description
    â”œâ”€ Metrics: JSON object (optional)
    â””â”€ Evidence Links: array of URLs (optional)
    â”‚
    â–¼
[Submits Form]
    â”‚
    â–¼
POST /api/ai-systems/[id]/risk-assessments
    â”‚
    â”œâ”€ Validates user authentication
    â”œâ”€ Validates required fields
    â”œâ”€ Checks if system exists (EU/MAS/UK assessments)
    â””â”€ Creates Supabase client
    â”‚
    â–¼
[Supabase Insert]
    â”‚
    â”œâ”€ Inserts into risk_assessments table
    â”œâ”€ RLS Policy checks: auth.uid() IS NOT NULL
    â””â”€ Returns created assessment
    â”‚
    â–¼
[Frontend receives response]
    â”‚
    â”œâ”€ Refreshes assessment list
    â”œâ”€ Hides form
    â””â”€ Shows success message
```

### 2. Viewing Risk Assessments

```
User Action
    â”‚
    â–¼
[Navigates to /ai-systems/[id]]
    â”‚
    â–¼
[Page loads â†’ useEffect triggers]
    â”‚
    â–¼
GET /api/ai-systems/[id]/risk-assessments
    â”‚
    â”œâ”€ Validates user authentication
    â””â”€ Creates Supabase client
    â”‚
    â–¼
[Supabase Query]
    â”‚
    â”œâ”€ SELECT * FROM risk_assessments
    â”œâ”€ WHERE ai_system_id = [id]
    â”œâ”€ RLS Policy checks: assessed_by = auth.uid() OR auth.uid() IS NOT NULL
    â””â”€ ORDER BY assessed_at DESC
    â”‚
    â–¼
[Returns array of assessments]
    â”‚
    â–¼
[Frontend displays in RiskTable.tsx]
    â”‚
    â”œâ”€ Shows category, risk level, mitigation status
    â”œâ”€ Shows assessment date
    â””â”€ Provides "View" button for each
```

### 3. Viewing Assessment Details

```
User Action
    â”‚
    â–¼
[Clicks "View" button on assessment]
    â”‚
    â–¼
[Opens RiskDetail.tsx modal]
    â”‚
    â”œâ”€ Displays full summary
    â”œâ”€ Shows all metrics (key-value pairs)
    â”œâ”€ Lists evidence links (clickable)
    â”œâ”€ Shows risk level badge
    â””â”€ Shows mitigation status
```

### 4. Calculating Overall Risk Level

```
User Action / Automatic
    â”‚
    â–¼
[Page loads or assessment created]
    â”‚
    â–¼
[Frontend calls calculateOverallRiskLevel()]
    â”‚
    â”œâ”€ Takes all assessments for the system
    â”œâ”€ Finds highest risk level:
    â”‚   â””â”€ Priority: high > medium > low
    â”œâ”€ Counts total assessments
    â””â”€ Counts mitigated assessments
    â”‚
    â–¼
[Displays overall risk badge in header]
    â”‚
    â””â”€ Red badge if "high"
    â””â”€ Yellow badge if "medium"
    â””â”€ Green badge if "low"
```

## ğŸ”„ Complete User Journey

### Scenario: User wants to assess bias risk for an AI system

```
1. USER NAVIGATES
   â””â”€ Goes to /dashboard
   â””â”€ Sees list of compliance assessments
   â””â”€ Clicks on an EU AI Act assessment
   â””â”€ Gets ID: "abc123-def456-..."

2. USER OPENS RISK ASSESSMENT PAGE
   â””â”€ Navigates to /ai-systems/abc123-def456-...
   â””â”€ Page loads, fetches existing assessments
   â””â”€ Sees "Risk Assessments" tab (default)

3. USER CREATES NEW ASSESSMENT
   â””â”€ Clicks "New Assessment" button
   â””â”€ Form appears (RiskForm.tsx)
   â””â”€ Selects:
      â€¢ Category: "Bias & Fairness"
      â€¢ Risk Level: "High"
      â€¢ Summary: "Model shows 15% disparity in loan approval rates..."
      â€¢ Evidence Links: ["https://docs.company.com/bias-audit.pdf"]
   â””â”€ Clicks "Create Assessment"

4. BACKEND PROCESSES
   â””â”€ API validates: category âœ“, risk_level âœ“, summary (min 10 chars) âœ“
   â””â”€ Checks if system ID exists in EU/MAS/UK tables
   â””â”€ Inserts into risk_assessments:
      {
        ai_system_id: "abc123-def456-...",
        category: "bias",
        risk_level: "high",
        summary: "...",
        assessed_by: [current_user_id],
        assessed_at: NOW(),
        mitigation_status: "not_started"
      }
   â””â”€ RLS Policy allows (authenticated user)

5. FRONTEND UPDATES
   â””â”€ Receives created assessment
   â””â”€ Refreshes assessment list
   â””â”€ Table now shows new assessment
   â””â”€ Overall risk level updates to "High" (if it was lower before)

6. USER VIEWS DETAILS
   â””â”€ Clicks "View" on the new assessment
   â””â”€ Modal opens (RiskDetail.tsx)
   â””â”€ Sees full summary, metrics, evidence links
   â””â”€ Can click evidence link to open PDF

7. USER UPDATES MITIGATION STATUS (Optional)
   â””â”€ Admin or assessor can update via API:
      PUT /api/risk-assessments/[assessmentId]
      {
        "mitigation_status": "in_progress"
      }
   â””â”€ RLS Policy checks: assessed_by = auth.uid() OR isAdmin
```

## ğŸ—„ï¸ Database Structure

### risk_assessments Table

```sql
risk_assessments
â”œâ”€â”€ id (UUID, Primary Key)
â”œâ”€â”€ ai_system_id (UUID) â†’ Links to EU/MAS/UK assessment ID
â”œâ”€â”€ category (TEXT) â†’ 'bias' | 'robustness' | 'privacy' | 'explainability'
â”œâ”€â”€ summary (TEXT) â†’ Risk description
â”œâ”€â”€ metrics (JSONB) â†’ Category-specific data
â”‚   â”œâ”€â”€ For bias: { demographic_parity: 0.85, ... }
â”‚   â”œâ”€â”€ For robustness: { accuracy: 0.94, ... }
â”‚   â”œâ”€â”€ For privacy: { data_leakage_risk: "Low", ... }
â”‚   â””â”€â”€ For explainability: { interpretability_score: 0.87, ... }
â”œâ”€â”€ risk_level (TEXT) â†’ 'low' | 'medium' | 'high'
â”œâ”€â”€ mitigation_status (TEXT) â†’ 'not_started' | 'in_progress' | 'mitigated'
â”œâ”€â”€ assessed_by (UUID) â†’ References auth.users(id)
â”œâ”€â”€ assessed_at (TIMESTAMP) â†’ When assessment was done
â”œâ”€â”€ evidence_links (TEXT[]) â†’ Array of URLs/files
â”œâ”€â”€ created_at (TIMESTAMP)
â””â”€â”€ updated_at (TIMESTAMP) â†’ Auto-updated by trigger
```

### Relationship to Existing Tables

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ eu_ai_act_check_    â”‚
â”‚ results             â”‚
â”‚ id: abc123...       â”‚â—„â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ ai_system_id
â”‚ mas_ai_risk_        â”‚    â”‚ (any UUID)
â”‚ assessments         â”‚    â”‚
â”‚ id: def456...       â”‚â—„â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ uk_ai_assessments   â”‚    â”‚
â”‚ id: ghi789...       â”‚â—„â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ risk_assessments    â”‚
                  â”‚ ai_system_id: ...   â”‚
                  â”‚ category: bias      â”‚
                  â”‚ risk_level: high    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Security Flow (RLS Policies)

### When User Views Assessments

```
1. User makes GET request
   â”‚
   â–¼
2. Supabase checks RLS Policy:
   "Users can view risk assessments for accessible systems"
   â”‚
   â”œâ”€ Condition 1: assessed_by = auth.uid()?
   â”‚  â””â”€ YES â†’ Allow
   â”‚  â””â”€ NO â†’ Check next
   â”‚
   â””â”€ Condition 2: auth.uid() IS NOT NULL?
      â””â”€ YES â†’ Allow (any authenticated user)
      â””â”€ NO â†’ Deny
```

### When User Creates Assessment

```
1. User makes POST request
   â”‚
   â–¼
2. Supabase checks RLS Policy:
   "Authenticated users can create risk assessments"
   â”‚
   â””â”€ Condition: auth.uid() IS NOT NULL?
      â””â”€ YES â†’ Allow
      â””â”€ NO â†’ Deny (401 Unauthorized)
```

### When User Updates Assessment

```
1. User makes PUT request
   â”‚
   â–¼
2. Supabase checks RLS Policy:
   "Admins and assessors can update risk assessments"
   â”‚
   â”œâ”€ Condition 1: assessed_by = auth.uid()?
   â”‚  â””â”€ YES â†’ Allow (original assessor)
   â”‚  â””â”€ NO â†’ Check next
   â”‚
   â””â”€ Condition 2: user_metadata.role = 'admin'?
      â””â”€ YES â†’ Allow
      â””â”€ NO â†’ Deny (403 Forbidden)
```

## ğŸ¯ Integration Points

### 1. With Compliance Assessments

```
Compliance Assessment (EU/MAS/UK)
    â”‚
    â””â”€ Has ID: "abc123..."
        â”‚
        â””â”€ Can be used as ai_system_id
            â”‚
            â””â”€ Multiple risk assessments can link to same system
                â”‚
                â”œâ”€ Bias assessment
                â”œâ”€ Robustness assessment
                â”œâ”€ Privacy assessment
                â””â”€ Explainability assessment
```

### 2. With Dashboard

```
Main Dashboard (/dashboard)
    â”‚
    â”œâ”€ Shows compliance assessments
    â”‚
    â””â”€ Can be extended to show:
        â”œâ”€ Overall risk level badge per system
        â””â”€ Link to risk assessments page
```

### 3. Overall Risk Calculation

```
For each system:
    â”‚
    â”œâ”€ Fetch all risk_assessments WHERE ai_system_id = [id]
    â”‚
    â”œâ”€ Find highest risk_level:
    â”‚   â””â”€ If any assessment = "high" â†’ Overall = "high"
    â”‚   â””â”€ Else if any = "medium" â†’ Overall = "medium"
    â”‚   â””â”€ Else â†’ Overall = "low"
    â”‚
    â””â”€ Display badge in UI
```

## ğŸ“ Example: Complete Flow

### User Story: "I want to assess bias risk for my loan approval AI system"

```
STEP 1: User has completed EU AI Act compliance assessment
   â””â”€ System ID: "eu-abc123-def456-ghi789"
   â””â”€ Stored in: eu_ai_act_check_results table

STEP 2: User navigates to risk assessment page
   â””â”€ URL: /ai-systems/eu-abc123-def456-ghi789
   â””â”€ Page component: app/ai-systems/[id]/page.tsx

STEP 3: Page fetches existing assessments
   â””â”€ API: GET /api/ai-systems/eu-abc123-def456-ghi789/risk-assessments
   â””â”€ Query: SELECT * FROM risk_assessments WHERE ai_system_id = 'eu-abc123...'
   â””â”€ Result: [] (no assessments yet)

STEP 4: User creates bias assessment
   â””â”€ Form data:
      {
        category: "bias",
        risk_level: "high",
        summary: "Model shows 15% approval rate disparity between demographic groups...",
        metrics: {
          demographic_parity: 0.85,
          equalized_odds: 0.92,
          protected_attributes: ["race", "gender"]
        },
        evidence_links: ["https://docs.company.com/bias-audit-2024.pdf"]
      }

STEP 5: API processes request
   â””â”€ Validates: category âœ“, risk_level âœ“, summary (50 chars) âœ“
   â””â”€ Checks system exists: Found in eu_ai_act_check_results âœ“
   â””â”€ Inserts into database:
      {
        id: "risk-xyz789-...",
        ai_system_id: "eu-abc123-def456-ghi789",
        category: "bias",
        risk_level: "high",
        summary: "...",
        metrics: {...},
        assessed_by: "user-uuid-123",
        assessed_at: "2024-12-15T10:30:00Z",
        mitigation_status: "not_started"
      }

STEP 6: Frontend updates
   â””â”€ Table shows new assessment
   â””â”€ Overall risk level badge changes to "High" (red)
   â””â”€ User can click "View" to see details

STEP 7: Later, user mitigates the risk
   â””â”€ Admin updates: PUT /api/risk-assessments/risk-xyz789-...
   â””â”€ Body: { "mitigation_status": "mitigated" }
   â””â”€ Database updates: mitigation_status = "mitigated"
   â””â”€ UI shows green "Mitigated" badge
```

## ğŸ”— Key Concepts

### 1. **Flexible System Linking**
- `ai_system_id` is just a UUID - no strict foreign key
- Can reference EU, MAS, UK assessments, or any system identifier
- Allows linking risk assessments to any system in your platform

### 2. **Category-Based Assessment**
- Each assessment focuses on ONE category
- A system can have multiple assessments (one per category)
- Categories are independent (bias assessment doesn't affect robustness)

### 3. **Overall Risk = Highest Individual Risk**
- If you have:
  - Bias: High
  - Robustness: Medium
  - Privacy: Low
  - Explainability: Medium
- Overall Risk = **High** (takes the highest)

### 4. **Governance Layer (Not ML Execution)**
- Stores assessment DATA
- Tracks mitigation STATUS
- Does NOT:
  - Train models
  - Fix bias automatically
  - Execute ML operations
- It's a documentation and tracking system

### 5. **RLS Security Model**
- **View**: Any authenticated user
- **Create**: Any authenticated user
- **Update**: Only assessor or admin
- **Delete**: Only admin

## ğŸ¨ UI Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /ai-systems/[id]                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Tabs: Overview | Risk | Comp  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Overall Risk: [High] Badge   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ [New Assessment] Button        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ RiskTable                      â”‚  â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚ â”‚ Category | Risk | Status  â”‚ â”‚  â”‚
â”‚  â”‚ â”‚ Bias     | High | [View]  â”‚ â”‚  â”‚
â”‚  â”‚ â”‚ Robust   | Med  | [View]  â”‚ â”‚  â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ RiskDetail Modal (when clicked)â”‚  â”‚
â”‚  â”‚ â€¢ Full summary                 â”‚  â”‚
â”‚  â”‚ â€¢ Metrics table                â”‚  â”‚
â”‚  â”‚ â€¢ Evidence links               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Next Steps for Integration

1. **Add to Compliance Detail Pages**
   - Add "View Risk Assessments" button on `/compliance/[id]`
   - Link to `/ai-systems/[id]?tab=risk-assessments`

2. **Dashboard Integration**
   - Show overall risk level badge in main dashboard table
   - Add filter by risk level

3. **Notifications**
   - Alert when high-risk assessment is created
   - Remind users of unmitigated high-risk assessments

4. **Reporting**
   - Export risk assessment reports
   - Generate risk trend charts over time
